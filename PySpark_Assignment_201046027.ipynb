{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Hello|\n",
      "+-----+\n",
      "|  SQL|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('FIRST SPARK APP').getOrCreate()\n",
    "df = spark.sql('''select 'SQL' as Hello''')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Test RDD Examples\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating RDDs\n",
    "# Using parallelize method\n",
    "# parallelize() method is used to create an RDD from a list\n",
    "rdd_par = spark.sparkContext.parallelize([\"Big Data \", \"Data Structures\", 'PySpark'])\n",
    "type((rdd_par))\n",
    "#rdd_par.collect() #ex for action (performed on that data set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create RDDs in three different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big Data ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating RDD using transformations\n",
    "rdd_trans = rdd_par.filter(lambda word:word.startswith('B'))\n",
    "rdd_trans.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating RDD using Data Sources\n",
    "# RDD can also be created from a text file using textFile() function of the SparkContext.\n",
    "rdd_ds = spark.sparkContext.textFile('spark.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count-> number, collect()->gives data\n",
    "rdd_ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big data is a term that describes the large volume of data – both structured and unstructured – that inundates a business on a day-to-day basis. But it’s not the amount of data that’s important. It’s what organizations do with the data that matters. Big data can be analyzed for insights that lead to better decisions and strategic business moves.',\n",
       " 'The term “big data” refers to data that is so large, fast or complex that it’s difficult or impossible to process using traditional methods. The act of accessing and storing large amounts of information for analytics has been around a long time. But the concept of big data gained momentum in the early 2000s when industry analyst Doug Laney articulated the now-mainstream definition of big data as the three V’s:',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_ds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_ds.flatMap(lambda word: word.split(' ')).count()\n",
    "# flatMap \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Big', 1),\n",
       " ('data', 1),\n",
       " ('is', 1),\n",
       " ('a', 1),\n",
       " ('term', 1),\n",
       " ('that', 1),\n",
       " ('describes', 1),\n",
       " ('the', 1),\n",
       " ('large', 1),\n",
       " ('volume', 1),\n",
       " ('of', 1),\n",
       " ('data', 1),\n",
       " ('–', 1),\n",
       " ('both', 1),\n",
       " ('structured', 1),\n",
       " ('and', 1),\n",
       " ('unstructured', 1),\n",
       " ('–', 1),\n",
       " ('that', 1),\n",
       " ('inundates', 1),\n",
       " ('a', 1),\n",
       " ('business', 1),\n",
       " ('on', 1),\n",
       " ('a', 1),\n",
       " ('day-to-day', 1),\n",
       " ('basis.', 1),\n",
       " ('But', 1),\n",
       " ('it’s', 1),\n",
       " ('not', 1),\n",
       " ('the', 1),\n",
       " ('amount', 1),\n",
       " ('of', 1),\n",
       " ('data', 1),\n",
       " ('that’s', 1),\n",
       " ('important.', 1),\n",
       " ('It’s', 1),\n",
       " ('what', 1),\n",
       " ('organizations', 1),\n",
       " ('do', 1),\n",
       " ('with', 1),\n",
       " ('the', 1),\n",
       " ('data', 1),\n",
       " ('that', 1),\n",
       " ('matters.', 1),\n",
       " ('Big', 1),\n",
       " ('data', 1),\n",
       " ('can', 1),\n",
       " ('be', 1),\n",
       " ('analyzed', 1),\n",
       " ('for', 1),\n",
       " ('insights', 1),\n",
       " ('that', 1),\n",
       " ('lead', 1),\n",
       " ('to', 1),\n",
       " ('better', 1),\n",
       " ('decisions', 1),\n",
       " ('and', 1),\n",
       " ('strategic', 1),\n",
       " ('business', 1),\n",
       " ('moves.', 1),\n",
       " ('The', 1),\n",
       " ('term', 1),\n",
       " ('“big', 1),\n",
       " ('data”', 1),\n",
       " ('refers', 1),\n",
       " ('to', 1),\n",
       " ('data', 1),\n",
       " ('that', 1),\n",
       " ('is', 1),\n",
       " ('so', 1),\n",
       " ('large,', 1),\n",
       " ('fast', 1),\n",
       " ('or', 1),\n",
       " ('complex', 1),\n",
       " ('that', 1),\n",
       " ('it’s', 1),\n",
       " ('difficult', 1),\n",
       " ('or', 1),\n",
       " ('impossible', 1),\n",
       " ('to', 1),\n",
       " ('process', 1),\n",
       " ('using', 1),\n",
       " ('traditional', 1),\n",
       " ('methods.', 1),\n",
       " ('The', 1),\n",
       " ('act', 1),\n",
       " ('of', 1),\n",
       " ('accessing', 1),\n",
       " ('and', 1),\n",
       " ('storing', 1),\n",
       " ('large', 1),\n",
       " ('amounts', 1),\n",
       " ('of', 1),\n",
       " ('information', 1),\n",
       " ('for', 1),\n",
       " ('analytics', 1),\n",
       " ('has', 1),\n",
       " ('been', 1),\n",
       " ('around', 1),\n",
       " ('a', 1),\n",
       " ('long', 1),\n",
       " ('time.', 1),\n",
       " ('But', 1),\n",
       " ('the', 1),\n",
       " ('concept', 1),\n",
       " ('of', 1),\n",
       " ('big', 1),\n",
       " ('data', 1),\n",
       " ('gained', 1),\n",
       " ('momentum', 1),\n",
       " ('in', 1),\n",
       " ('the', 1),\n",
       " ('early', 1),\n",
       " ('2000s', 1),\n",
       " ('when', 1),\n",
       " ('industry', 1),\n",
       " ('analyst', 1),\n",
       " ('Doug', 1),\n",
       " ('Laney', 1),\n",
       " ('articulated', 1),\n",
       " ('the', 1),\n",
       " ('now-mainstream', 1),\n",
       " ('definition', 1),\n",
       " ('of', 1),\n",
       " ('big', 1),\n",
       " ('data', 1),\n",
       " ('as', 1),\n",
       " ('the', 1),\n",
       " ('three', 1),\n",
       " ('V’s:', 1),\n",
       " ('', 1),\n",
       " ('', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd = rdd_ds.flatMap(lambda word: word.split(' '))\n",
    "#word_rdd.collect()\n",
    "freq_words = word_rdd.map(lambda word: (word, 1))\n",
    "#freq_words.collect()\n",
    "freq_words.reduceByKey(lambda a,b : a+b)\n",
    "# reduceByKey has a built in accumilator(initial val is zero)\n",
    "# words are key : 1 is value\n",
    "# each ele we created a tuple\n",
    "freq_words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Big data'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating RDDs\n",
    "# Using parallelize method\n",
    "rdd_par = spark.sparkContext.parallelize([\"Big data\", \"is a term that describes the large volume of data \" ,\"both structured and unstructured\"])\n",
    "type(rdd_par)\n",
    "rdd_par.collect()\n",
    "rdd_par.count()\n",
    "rdd_par.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big data is a term that describes the large volume of data – both structured and unstructured – that inundates a business on a day-to-day basis. But it’s not the amount of data that’s important. It’s what organizations do with the data that matters. Big data can be analyzed for insights that lead to better decisions and strategic business moves.',\n",
       " 'The term “big data” refers to data that is so large, fast or complex that it’s difficult or impossible to process using traditional methods. The act of accessing and storing large amounts of information for analytics has been around a long time. But the concept of big data gained momentum in the early 2000s when industry analyst Doug Laney articulated the now-mainstream definition of big data as the three V’s:',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating RDD using Data Sources\n",
    "rdd_ds = spark.sparkContext.textFile('spark.txt')\n",
    "rdd_ds.count()\n",
    "rdd_ds.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read a text file and count number of words in the file using RDD operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_ds = spark.sparkContext.textFile('spark.txt')\n",
    "word_rdd = rdd_ds.flatMap(lambda word: word.split(' '))\n",
    "word_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a program to find the word frequency in a given file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 2),\n",
       " ('term', 2),\n",
       " ('large', 2),\n",
       " ('of', 6),\n",
       " ('both', 1),\n",
       " ('inundates', 1),\n",
       " ('business', 2),\n",
       " ('basis.', 1),\n",
       " ('But', 2),\n",
       " ('it’s', 2),\n",
       " ('amount', 1),\n",
       " ('It’s', 1),\n",
       " ('organizations', 1),\n",
       " ('do', 1),\n",
       " ('matters.', 1),\n",
       " ('strategic', 1),\n",
       " ('moves.', 1),\n",
       " ('The', 2),\n",
       " ('refers', 1),\n",
       " ('large,', 1),\n",
       " ('impossible', 1),\n",
       " ('process', 1),\n",
       " ('using', 1),\n",
       " ('traditional', 1),\n",
       " ('methods.', 1),\n",
       " ('act', 1),\n",
       " ('accessing', 1),\n",
       " ('storing', 1),\n",
       " ('amounts', 1),\n",
       " ('analytics', 1),\n",
       " ('around', 1),\n",
       " ('long', 1),\n",
       " ('in', 1),\n",
       " ('when', 1),\n",
       " ('analyst', 1),\n",
       " ('Laney', 1),\n",
       " ('as', 1),\n",
       " ('three', 1),\n",
       " ('V’s:', 1),\n",
       " ('', 2),\n",
       " ('Big', 2),\n",
       " ('data', 8),\n",
       " ('a', 4),\n",
       " ('that', 6),\n",
       " ('describes', 1),\n",
       " ('the', 7),\n",
       " ('volume', 1),\n",
       " ('–', 2),\n",
       " ('structured', 1),\n",
       " ('and', 3),\n",
       " ('unstructured', 1),\n",
       " ('on', 1),\n",
       " ('day-to-day', 1),\n",
       " ('not', 1),\n",
       " ('that’s', 1),\n",
       " ('important.', 1),\n",
       " ('what', 1),\n",
       " ('with', 1),\n",
       " ('can', 1),\n",
       " ('be', 1),\n",
       " ('analyzed', 1),\n",
       " ('for', 2),\n",
       " ('insights', 1),\n",
       " ('lead', 1),\n",
       " ('to', 3),\n",
       " ('better', 1),\n",
       " ('decisions', 1),\n",
       " ('“big', 1),\n",
       " ('data”', 1),\n",
       " ('so', 1),\n",
       " ('fast', 1),\n",
       " ('or', 2),\n",
       " ('complex', 1),\n",
       " ('difficult', 1),\n",
       " ('information', 1),\n",
       " ('has', 1),\n",
       " ('been', 1),\n",
       " ('time.', 1),\n",
       " ('concept', 1),\n",
       " ('big', 2),\n",
       " ('gained', 1),\n",
       " ('momentum', 1),\n",
       " ('early', 1),\n",
       " ('2000s', 1),\n",
       " ('industry', 1),\n",
       " ('Doug', 1),\n",
       " ('articulated', 1),\n",
       " ('now-mainstream', 1),\n",
       " ('definition', 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd = rdd_ds.flatMap(lambda word: word.split(' '))\n",
    "freq_words = word_rdd.map(lambda word: (word, 1))\n",
    "freq_words.reduceByKey(lambda a, b: a + b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a program to convert all words in a file to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BIG DATA IS A TERM THAT DESCRIBES THE LARGE VOLUME OF DATA – BOTH STRUCTURED AND UNSTRUCTURED – THAT INUNDATES A BUSINESS ON A DAY-TO-DAY BASIS. BUT IT’S NOT THE AMOUNT OF DATA THAT’S IMPORTANT. IT’S WHAT ORGANIZATIONS DO WITH THE DATA THAT MATTERS. BIG DATA CAN BE ANALYZED FOR INSIGHTS THAT LEAD TO BETTER DECISIONS AND STRATEGIC BUSINESS MOVES.',\n",
       " 'THE TERM “BIG DATA” REFERS TO DATA THAT IS SO LARGE, FAST OR COMPLEX THAT IT’S DIFFICULT OR IMPOSSIBLE TO PROCESS USING TRADITIONAL METHODS. THE ACT OF ACCESSING AND STORING LARGE AMOUNTS OF INFORMATION FOR ANALYTICS HAS BEEN AROUND A LONG TIME. BUT THE CONCEPT OF BIG DATA GAINED MOMENTUM IN THE EARLY 2000S WHEN INDUSTRY ANALYST DOUG LANEY ARTICULATED THE NOW-MAINSTREAM DEFINITION OF BIG DATA AS THE THREE V’S:',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd_upper = rdd_ds.map(lambda word: word.upper())\n",
    "word_rdd_upper.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a program to convert all words in a file to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['big data is a term that describes the large volume of data – both structured and unstructured – that inundates a business on a day-to-day basis. but it’s not the amount of data that’s important. it’s what organizations do with the data that matters. big data can be analyzed for insights that lead to better decisions and strategic business moves.',\n",
       " 'the term “big data” refers to data that is so large, fast or complex that it’s difficult or impossible to process using traditional methods. the act of accessing and storing large amounts of information for analytics has been around a long time. but the concept of big data gained momentum in the early 2000s when industry analyst doug laney articulated the now-mainstream definition of big data as the three v’s:',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd_lower = rdd_ds.map(lambda word: word.lower())\n",
    "word_rdd_lower.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a program to capitalize first leter of each words in file (use string capitalize() method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big',\n",
       " 'Data',\n",
       " 'Is',\n",
       " 'A',\n",
       " 'Term',\n",
       " 'That',\n",
       " 'Describes',\n",
       " 'The',\n",
       " 'Large',\n",
       " 'Volume',\n",
       " 'Of',\n",
       " 'Data',\n",
       " '–',\n",
       " 'Both',\n",
       " 'Structured',\n",
       " 'And',\n",
       " 'Unstructured',\n",
       " '–',\n",
       " 'That',\n",
       " 'Inundates',\n",
       " 'A',\n",
       " 'Business',\n",
       " 'On',\n",
       " 'A',\n",
       " 'Day-to-day',\n",
       " 'Basis.',\n",
       " 'But',\n",
       " 'It’s',\n",
       " 'Not',\n",
       " 'The',\n",
       " 'Amount',\n",
       " 'Of',\n",
       " 'Data',\n",
       " 'That’s',\n",
       " 'Important.',\n",
       " 'It’s',\n",
       " 'What',\n",
       " 'Organizations',\n",
       " 'Do',\n",
       " 'With',\n",
       " 'The',\n",
       " 'Data',\n",
       " 'That',\n",
       " 'Matters.',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'Can',\n",
       " 'Be',\n",
       " 'Analyzed',\n",
       " 'For',\n",
       " 'Insights',\n",
       " 'That',\n",
       " 'Lead',\n",
       " 'To',\n",
       " 'Better',\n",
       " 'Decisions',\n",
       " 'And',\n",
       " 'Strategic',\n",
       " 'Business',\n",
       " 'Moves.',\n",
       " 'The',\n",
       " 'Term',\n",
       " '“big',\n",
       " 'Data”',\n",
       " 'Refers',\n",
       " 'To',\n",
       " 'Data',\n",
       " 'That',\n",
       " 'Is',\n",
       " 'So',\n",
       " 'Large,',\n",
       " 'Fast',\n",
       " 'Or',\n",
       " 'Complex',\n",
       " 'That',\n",
       " 'It’s',\n",
       " 'Difficult',\n",
       " 'Or',\n",
       " 'Impossible',\n",
       " 'To',\n",
       " 'Process',\n",
       " 'Using',\n",
       " 'Traditional',\n",
       " 'Methods.',\n",
       " 'The',\n",
       " 'Act',\n",
       " 'Of',\n",
       " 'Accessing',\n",
       " 'And',\n",
       " 'Storing',\n",
       " 'Large',\n",
       " 'Amounts',\n",
       " 'Of',\n",
       " 'Information',\n",
       " 'For',\n",
       " 'Analytics',\n",
       " 'Has',\n",
       " 'Been',\n",
       " 'Around',\n",
       " 'A',\n",
       " 'Long',\n",
       " 'Time.',\n",
       " 'But',\n",
       " 'The',\n",
       " 'Concept',\n",
       " 'Of',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'Gained',\n",
       " 'Momentum',\n",
       " 'In',\n",
       " 'The',\n",
       " 'Early',\n",
       " '2000s',\n",
       " 'When',\n",
       " 'Industry',\n",
       " 'Analyst',\n",
       " 'Doug',\n",
       " 'Laney',\n",
       " 'Articulated',\n",
       " 'The',\n",
       " 'Now-mainstream',\n",
       " 'Definition',\n",
       " 'Of',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'As',\n",
       " 'The',\n",
       " 'Three',\n",
       " 'V’s:',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdds = rdd_ds.flatMap(lambda word: word.split(' '))\n",
    "word_rdd_capitalized = word_rdds.map(lambda word: word.capitalize())\n",
    "word_rdd_capitalized.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Find the longest length of word from given set of words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd = rdd_ds.flatMap(lambda word: word.split(' '))\n",
    "word_rdd_length = word_rdd.map(lambda word:len(word))\n",
    "\n",
    "max(word_rdd_length.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Map the Registration numbers to corresponding branch. 6000 series BDA, 9000 series HDA, 1000 series ML, 2000 series VLSI, 3000 series ES, 4000 series MSc, 5000 series CC. Given registration number, generate a key-value pair of Registration Number and Corresponding Branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key, value are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(6002, 'BDA'), (3050, 'ES'), (2500, 'VLSI'), (1500, 'ML'), (9050, 'HDA')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = [6002, 3050, 2500, 1500, 9050]\n",
    "rdd_par = spark.sparkContext.parallelize(series)\n",
    "rdd_sequence = rdd_par.map(lambda series: (series, 'ML') if (series >= 1000 and series < 1999)  \n",
    "                           else ((series, 'VLSI') if (series >= 2000 and series < 2999)\n",
    "                           else ((series, 'ES') if (series >= 3000 and series < 3999) \n",
    "                           else ((series, 'MSc') if (series >= 4000 and series < 4999) \n",
    "                           else ((series, 'CC') if (series >= 5000 and series < 5999) \n",
    "                           else ((series, 'BDA') if (series >= 6000 and series < 6999)\n",
    "                           else ((series, 'HDA') if (series >= 9000 and series < 9999) else (series, 'NA'))))))))\n",
    "\n",
    "print(\"Key, value are: \")\n",
    "rdd_sequence.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Text file contain numbers. Numbers are separated by one white space. There is no order to store the numbers. One line may contain one or more numbers. Find the maximum, minimum, sum and mean of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_ds = spark.sparkContext.textFile('numbers.txt')\n",
    "rdd_ds_num = rdd_ds.flatMap(lambda n: n.split(' '))\n",
    "rdd_l=rdd_ds_num.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [i for i in rdd_l if i] # list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [int(i) for i in test_list if i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1082"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.61538461538461"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_list)/len(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. A text file (citizen.txt) contains data about citizens of country.\n",
    "Fields (information in file) are Name, dob, Phone, email and state name. \n",
    "Another file contains mapping of state names to state code like Karnataka is codes as KA, \n",
    "TamilNadu as TN, Kerala KL etc. Compress the citizen.txt file by changing full state name to state code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+-------------+----------+\n",
      "|  Name|       dob|     Phone|        email|state code|\n",
      "+------+----------+----------+-------------+----------+\n",
      "|Mahesh|16-07-1990|8978866441| hi@gmail.com|        KA|\n",
      "|Suresh|10-10-1992|8978866442|hi2@gmail.com|        KL|\n",
      "|Ramesh|15-05-1991|9030915551|hi1@gmail.com|        TN|\n",
      "+------+----------+----------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rdd_ds_citizen = spark.sparkContext.textFile('citizen.txt')\n",
    "rdd_ds_statecode = spark.sparkContext.textFile('statecode.txt')\n",
    "rdd_ds_citizen = rdd_ds_citizen.map(lambda citizen: citizen.split(', '))\n",
    "rdd_ds_statecode = rdd_ds_statecode.map(lambda state: state.split(', '))\n",
    "citizen = spark.createDataFrame(rdd_ds_citizen, ['Name', 'dob', 'Phone', 'email', 'state name'])\n",
    "statecodes = spark.createDataFrame(rdd_ds_statecode, ['state name', 'state code'])\n",
    "citizen.collect()\n",
    "statecodes.collect()\n",
    "citizen.join(statecodes, on='state name', how='left').drop('state name').show()\n",
    "citizen.write.csv('citizen_compressed.csv')\n",
    "citizen.rdd.map(lambda x: x[0] + \",\" + str(x)).repartition(1).saveAsTextFile('Text/citizen.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
